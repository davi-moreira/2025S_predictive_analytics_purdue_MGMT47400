[
  {
    "objectID": "index.html#course-description-and-objectives",
    "href": "index.html#course-description-and-objectives",
    "title": "MGMT 47400: Predictive Analytics",
    "section": "Course Description and Objectives",
    "text": "Course Description and Objectives\nThe course enables students to navigate the entire predictive analytics pipeline skillfully—from data preparation and exploration to modeling, assessment, and interpretation. Throughout the course, learners engage with real-world examples and hands-on labs emphasizing essential programming and analytical skills. By exploring topics such as linear and logistic regression, classification, resampling methods, regularization techniques, tree-based approaches, support vector machines, and advanced learning paradigms (including neural networks and unsupervised methods), participants gain a robust theoretical understanding and practical experience. Ultimately, students will leave the course equipped to apply predictive models to data-driven problems, communicate their findings to diverse audiences, and critically evaluate model performance to inform strategic decision-making across various business contexts.\nCourse Website: https://davi-moreira.github.io/2025S_predictive_analytics_purdue_MGMT47400/\n\nInstructor: Professor Davi Moreira\n\nEmail: dmoreira@purdue.edu\nOffice: Young Hall 414\nVirtual Office hours: Zoom link in your Course Brightspace Page\nIndividual Appointments: Book time with me through the link in the course syllabus on your Course Brightspace Page or by appointment.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "MGMT 47400: Predictive Analytics",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the conclusion of this course, students will be able to:\n\nExplain Core Predictive Analytics Concepts: Articulate key principles of statistical learning and predictive analytics, including fundamental terminology, modeling strategies, and the role of data-driven insights in business contexts.\nPrepare and Explore Data Effectively: Demonstrate proficiency in cleaning, organizing, and exploring datasets, applying tools and techniques for data preprocessing, feature engineering, and exploratory analysis.\nImplement Diverse Modeling Techniques: Construct predictive models using linear and logistic regression, classification methods, resampling procedures, and regularization techniques.\nAssess and Interpret Model Performance: Evaluate the accuracy, robustness, and interpretability of predictive models, critically examining issues such as overfitting, bias-variance trade-offs, and cross-validation results.\nCommunicate Analytical Findings: Present analytical outcomes and model interpretations to technical and non-technical audiences, crafting clear, concise, and visually effective reports or presentations.\nIntegrate Predictive Analytics into Decision-Making: Recommend actionable strategies based on model findings, demonstrating the ability to align analytical results with organizational objectives and inform evidence-based decision processes.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "MGMT 47400: Predictive Analytics",
    "section": "Course Materials",
    "text": "Course Materials\n\nTextbooks (Required): ISLP James, G., Witten, D., Hastie, T., & Tibshirani, R. (2023). An Introduction to Statistical Learning with Applications in Python. Springer. https://doi.org/10.1007/978-1-0716-2926-2. Download here: https://www.statlearning.com/\nComputing (Required): A laptop or desktop with internet access and the capability to run Python code through Google Colab: https://colab.research.google.com/.\nSoftware (Required): Google Colab is a cloud-based platform that requires no software installation on your local machine; it is accessible through a modern web browser such as Google Chrome, Mozilla Firefox, Microsoft Edge, or Safari. To use Google Colab, you need a Google account and a stable internet connection. While optional, having tools like a local Python installation (e.g., Anaconda) or a Python IDE (e.g., Jupyter Notebook or VS Code) can be helpful for offline development. Additionally, browser extensions, such as those for VS Code integration, can enhance your experience but are not required. This makes Google Colab convenient and easy for Python programming and data science tasks.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-infra-structure",
    "href": "index.html#course-infra-structure",
    "title": "MGMT 47400: Predictive Analytics",
    "section": "Course Infra-structure",
    "text": "Course Infra-structure\nBrightspace: The Course Brightspace Page https://purdue.brightspace.com/ should be checked on a regular basis for announcements and course material.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "syllabus.html#course-description-and-objectives",
    "href": "syllabus.html#course-description-and-objectives",
    "title": "Syllabus",
    "section": "Course Description and Objectives",
    "text": "Course Description and Objectives\nThe course enables students to navigate the entire predictive analytics pipeline skillfully—from data preparation and exploration to modeling, assessment, and interpretation. Throughout the course, learners engage with real-world examples and hands-on labs emphasizing essential programming and analytical skills. By exploring topics such as linear and logistic regression, classification, resampling methods, regularization techniques, tree-based approaches, support vector machines, and advanced learning paradigms (including neural networks and unsupervised methods), participants gain a robust theoretical understanding and practical experience. Ultimately, students will leave the course equipped to apply predictive models to data-driven problems, communicate their findings to diverse audiences, and critically evaluate model performance to inform strategic decision-making across various business contexts.\nCourse Website: https://davi-moreira.github.io/2025S_predictive_analytics_purdue_MGMT47400/",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "Instructor",
    "text": "Instructor\n\nInstructor: Professor Davi Moreira\n\nEmail: dmoreira@purdue.edu\nOffice: Young Hall 414\nVirtual Office hours: Zoom link in your Course Brightspace Page\nIndividual Appointments: Book time with me through the link in the course syllabus on your Course Brightspace Page or by appointment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#learning-outcomes",
    "href": "syllabus.html#learning-outcomes",
    "title": "Syllabus",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the conclusion of this course, students will be able to:\n\nExplain Core Predictive Analytics Concepts: Articulate key principles of statistical learning and predictive analytics, including fundamental terminology, modeling strategies, and the role of data-driven insights in business contexts.\nPrepare and Explore Data Effectively: Demonstrate proficiency in cleaning, organizing, and exploring datasets, applying tools and techniques for data preprocessing, feature engineering, and exploratory analysis.\nImplement Diverse Modeling Techniques: Construct predictive models using linear and logistic regression, classification methods, resampling procedures, and regularization techniques.\nAssess and Interpret Model Performance: Evaluate the accuracy, robustness, and interpretability of predictive models, critically examining issues such as overfitting, bias-variance trade-offs, and cross-validation results.\nCommunicate Analytical Findings: Present analytical outcomes and model interpretations to technical and non-technical audiences, crafting clear, concise, and visually effective reports or presentations.\nIntegrate Predictive Analytics into Decision-Making: Recommend actionable strategies based on model findings, demonstrating the ability to align analytical results with organizational objectives and inform evidence-based decision processes.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\n\nTextbooks (Required): ISLP James, G., Witten, D., Hastie, T., & Tibshirani, R. (2023). An Introduction to Statistical Learning with Applications in Python. Springer. https://doi.org/10.1007/978-1-0716-2926-2. Download here: https://www.statlearning.com/\nComputing (Required): A laptop or desktop with internet access and the capability to run Python code through Google Colab: https://colab.research.google.com/.\nSoftware (Required): Google Colab is a cloud-based platform that requires no software installation on your local machine; it is accessible through a modern web browser such as Google Chrome, Mozilla Firefox, Microsoft Edge, or Safari. To use Google Colab, you need a Google account and a stable internet connection. While optional, having tools like a local Python installation (e.g., Anaconda) or a Python IDE (e.g., Jupyter Notebook or VS Code) can be helpful for offline development. Additionally, browser extensions, such as those for VS Code integration, can enhance your experience but are not required. This makes Google Colab convenient and easy for Python programming and data science tasks.\n\n\nCourse Infra-structure\nBrightspace: The Course Brightspace Page https://purdue.brightspace.com/ should be checked on a regular basis for announcements and course material.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assessments",
    "href": "syllabus.html#assessments",
    "title": "Syllabus",
    "section": "Assessments",
    "text": "Assessments\nAs part of a university-wide initiative, the Business School has adopted an Official Grading Policy that caps the overall class GPA at 3.3. Final letter grades are determined by curving final percentages, subject to any extra-credit exceptions discussed in this syllabus. While you will see your final percentage in Brightspace, individual grade thresholds will not be disclosed before official submissions.\n\n\n\nAssessment\nWeight\n\n\n\n\nAttendance/Participation\n10%\n\n\nQuizzes\n20%\n\n\nHomework\n30%\n\n\nFinal Project\n40%\n\n\n\n\nAttendance and Participation\nAttend class, participate in activities, and complete any participatory exercises. Random attendance checks will be used to measure involvement. According to Purdue regulations, students are expected to attend every class/lab meeting for which they are registered.\n\n\nQuizzes\nRegular quizzes based on lecture material will be administered, with no drops. Due dates and details will be on Brightspace. Quizzes help reinforce content and maintain steady engagement.\n\n\nHomework\nHomework assignments offer practical, hands-on exposure to data mining tasks. Expect multiple-choice questions requiring analysis of provided results. Deadlines will be posted in Brightspace. These assignments are crucial for building technical and analytical skills.\n\n\nFinal Project\nIn groups, students will complete a practical predictive analytics project culminating in a poster presentation at the Undergraduate Research Conference. A comprehensive set of project guidelines will be provided, and the assessment structure will adhere to the following criteria:\n\nMilestone Deliverables (40%): Students will submit incremental project components on specific due dates. These deliverables allow for early feedback and ensure steady progress throughout the semester. Grades will reflect each milestone’s clarity, completeness, and timely submission.\nPeer Evaluation (20%): To encourage accountability and productive teamwork, students will evaluate their peers’ contributions. These assessments help ensure balanced participation and measure collaborative effectiveness.\nPoster Presentation at the Purdue Undergraduate Research Conference (40%): A poster template and assessment rubric will be shared, and you are encouraged to review previous award-winning student posters for inspiration. Your final posters must be submitted by the due date indicated in the syllabus, after which they will be printed and distributed during a dedicated Poster Presentation Preparation class. Additional details on the conference can be found at https://www.purdue.edu/undergrad-research/conferences/index.php. As the event may not coincide with our regular class time, please communicate with your other course instructors in advance regarding potential scheduling conflicts. If any issues arise, please let me know. We will not hold our usual class immediately following the Poster Presentation, allowing you time to rest and catch up on other coursework. Consult the course schedule for further details.\n\n\n\nGrade Challenges\nGrades and solutions will be posted soon after each assignment deadline. Students have 7 calendar days from the grade posting to submit any challenge (3 days for the final two quizzes and homework assignments). Challenges must be based on legitimate discrepancies regarding data mining principles or grading accuracy.\n\nReview posted solutions thoroughly.\n\nIf you suspect an error, email Dr. Moreira with:\n\nCourse name, section, and lecture day/time\n\nYour name and Student ID\n\nAssignment/Exam Title or Number\n\nSpecific deduction questioned\n\nClear rationale referencing solutions or rubrics\n\n\n\nNo grades will be discussed in-class. Please use office hours for clarifications. After the 7-day (or 3-day) window, grades are final.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies-and-additional-details",
    "href": "syllabus.html#course-policies-and-additional-details",
    "title": "Syllabus",
    "section": "Course Policies and Additional Details",
    "text": "Course Policies and Additional Details\n\nExtra Credit Opportunities\n\nCheck the Course Syllabus document on Brightspace for details.\n\n\n\nAI Policy\n\nYou may use AI tools to support your learning (e.g., clarifying concepts, generating examples), but:\n\nDo not use AI for requesting solutions or exams.\n\nPractice refining prompts to get better AI outputs.\n\nVerify all AI-generated content for accuracy.\n\nCite any AI usage in your documents.\n\n\n\n\nAdditional Information\nRefer to Brightspace for deadlines, academic integrity policies, accommodations, CAPS information, and non-discrimination statements.\n\n\nSubject to Change Policy\nWhile we will endeavor to maintain the course schedule, the syllabus may be adjusted to accommodate the learning pace and needs of the class.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#schedule",
    "href": "syllabus.html#schedule",
    "title": "Syllabus",
    "section": "Schedule",
    "text": "Schedule",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\nTopic\nReadings ISLP\nMaterial*\nSupplementary Materials\n\n\n\n\nWeek 1\nSyllabus, Logistics, and Introduction.\nCh. 1; Ch. 2;\nslidesbook lab\n- Video: Statistical Learning: 2.1 Introduction to Regression Models- Video: Statistical Learning: 2.2 Dimensionality and Structured Models- Video: Statistical Learning: 2.3 Model Selection and Bias Variance Tradeoff- Video: Statistical Learning: 2.4 Classification- Video: Statistical Learning: 2.Py Data Types, Arrays, and Basics - 2023- Video: Statistical Learning: 2.Py.3 Graphics - 2023- Video: Statistical Learning: 2.Py Indexing and Dataframes - 2023\n\n\nWeek 2\nLinear Regression\nCh. 3.\nslidesbook lab\n- Video: Statistical Learning: 3.1 Simple linear regression- Video: Statistical Learning: 3.2 Hypothesis Testing and Confidence Intervals- Video: Statistical Learning: 3.3 Multiple Linear Regression- Video: Statistical Learning: 3.4 Some important questions- Video: Statistical Learning: 3.5 Extensions of the Linear Model- Video: Statistical Learning: 3.Py Linear Regression and statsmodels Package - 2023- Video: Statistical Learning: 3.Py Multiple Linear Regression Package - 2023- Video: Statistical Learning: 3.Py Interactions, Qualitative Predictors and Other Details I 2023\n\n\n\n* The course slides and labs are based on the ISLP book, “An Introduction to Statistical Learning with Applications in Python” by James, G., Witten, D., Hastie, T., and Tibshirani, R., and have been adapted to suit the specific needs of our course.",
    "crumbs": [
      "Schedule and Material"
    ]
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#overview",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#overview",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nStructured Data\nUnstructured Data\nDatabases\nRelational Databases\n\n\n\nNon Relational Databases\nMeta Data and Dictionary (code book)"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#what-is-data-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#what-is-data-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "What is Data?",
    "text": "What is Data?\n\n\n\n\nData refers to raw, unprocessed facts, figures, and symbols that represent information about the world around us. Data can take many forms, such as numbers, text, images, audio, and video, and it can be quantitative (numerical) or qualitative (categorical).\n\n\n\nData (Wiki)"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#types-of-data-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#types-of-data-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Types of Data",
    "text": "Types of Data\n\n\nStructured Data: Data that is organized in a defined format, such as rows and columns in a database (e.g., an Excel spreadsheet).\nUnstructured Data: Data that does not have a predefined structure, such as text, emails, social media posts, videos, and images.\nSemi-Structured Data: Data that does not conform to a strict structure but contains tags or markers to separate elements (e.g., XML or JSON files)."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#structured-business-data",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#structured-business-data",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Structured Business Data",
    "text": "Structured Business Data\n\n\nBusiness data refers to the information gathered by an organization, such as customer data, financial data, sales data, employee data, and more. Business data can come from a wide variety of sources - from customers’ purchase transactions and social media activities to market research and financial reports.\n\nBecause structured data is typically organized in a specific format that can be easily searched and analyzed, most business analytics are designed and applied to structured data. This course will focus solely on using and analyzing structured data."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#introduction-to-databases-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#introduction-to-databases-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Introduction to Databases",
    "text": "Introduction to Databases\n\n\n\n\nA Database is a structured collection of data, typically managed by a Database Management System (DBMS) to efficiently store, retrieve, and manage data for various applications."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#the-relational-model-1970s",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#the-relational-model-1970s",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "The Relational Model: 1970s",
    "text": "The Relational Model: 1970s\n\n\n\n\n\n\n\n\n\n\n\n\n\nEdgar F. Codd\n\n\n\n\nEdgar F. Codd: Proposed the relational model in 1970, which became the foundation for modern databases.\nRDBMS: A Relational Database Management System (RDBMS) is used to maintain relational databases.\nSQL: Structured Query Language (SQL) was developed to interact (query and update) with relational databases.\nAdoption: The relational model became dominant in the 1980s, with systems like Oracle, IBM DB2, and Microsoft SQL Server emerging. Nowadays, open-source systems like MySQL are used by big companies to handle their relational data."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#the-rise-of-nosql-2000s",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#the-rise-of-nosql-2000s",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "The Rise of NoSQL: 2000s",
    "text": "The Rise of NoSQL: 2000s\n\nLimitations of RDBMS: Traditional relational databases struggled with the scale and complexity of modern web applications.\n\nExample: A social media platform with millions of users posting, commenting, and liking content simultaneously.\nLimitation: RDBMS typically scale vertically (adding more power to a single server), which becomes increasingly expensive and challenging as the database grows. In contrast, NoSQL databases like Cassandra or MongoDB are designed to scale horizontally (adding more servers), making them better suited for handling such large-scale data across distributed systems.\n\nNoSQL Databases: Emerged to address these challenges. They offer flexibility, scalability, and performance improvements. They are designed to scale horizontally (adding more servers), making them better suited for handling such large-scale data across distributed systems.\n\nTypes: Document (e.g., MongoDB), Key-Value (e.g., Redis), Column-Family (e.g., Cassandra), and Graph (e.g., Neo4j).\nUse Cases: Ideal for big data, handling unstructured data, real-time web applications, and distributed systems."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#modern-database-trends",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#modern-database-trends",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Modern Database Trends",
    "text": "Modern Database Trends\n\n\nNewSQL: Combines the scalability of NoSQL with the Atomicity, Consistency, Isolation, and Durability (ACID) guarantees of traditional relational databases (e.g., Google Spanner).\nCloud Databases: The adoption of cloud computing has led to the rise of managed database services (e.g., Amazon RDS, Google Cloud SQL).\nData Lakes: A storage repository that holds vast amounts of raw data in its native format (e.g., AWS S3, Azure Data Lake)."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Relational Database",
    "text": "Relational Database\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA relational database links data tables through pre-defined and shared fields in various data tables, establishing relationships.\nThis permits more efficient organization and utilization of data across multiple tables.\nMoreover, a relational database serves as a potent tool for handling extensive data volumes and managing complex data structures."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-2",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-2",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Relational Database",
    "text": "Relational Database\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery 1: Flights from a Specific Carrier\n\n\nSELECT flights.year, flights.month, flights.day, \n       flights.flight, airlines.names AS airline_name\nFROM flights\nJOIN airlines ON flights.carrier = airlines.carrier\nWHERE airlines.names = 'American Airlines';  \n-- Replace 'American Airlines' with the desired carrier name"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-3",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-3",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Relational Database",
    "text": "Relational Database\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery 2: Weather Conditions at the Time of a Specific Flight\n\n\nSELECT flights.flight, flights.origin, \n        flights.dest, weather.*\nFROM flights\nJOIN weather \nON flights.year = weather.year AND\n   flights.month = weather.month AND\n   flights.day = weather.day AND\n   flights.hour = weather.hour AND\n   flights.origin = weather.origin\nWHERE flights.flight = 'AA123';  \n-- Replace 'AA123' with the desired flight number"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-4",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#relational-database-4",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Relational Database",
    "text": "Relational Database\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery 3: Count of Flights Per Airport\n\n\n\nSELECT airports.faa, \n        COUNT(flights.flight) AS flight_count\nFROM flights\nJOIN airports ON flights.origin = airports.faa\nGROUP BY airports.faa\nORDER BY flight_count DESC;"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-warehouse",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-warehouse",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Data Warehouse",
    "text": "Data Warehouse\n\n\nA Data Warehouse is a large and comprehensive storage system that consolidates data from various sources, including relational databases, into a centralized repository, much like a university campus that encompasses buildings of various functions.\n\nThe primary purpose of a data warehouse is to facilitate data storage, reporting, and analysis for business intelligence and decision-making purposes."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#information-management-system-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#information-management-system-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Information Management System",
    "text": "Information Management System\n\n\nThe primary goal of an Information Management System (IMS) is to ensure that accurate, timely, and relevant information is generated and available to the right people at the right time, enabling efficient and informed decision-making processes."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#information-management-system-2",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#information-management-system-2",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Information Management System",
    "text": "Information Management System\n\n\nKey Components: Data sources, ETL (Extract, Transform, Load), Data Warehouse, OLAP Engine, and Analytic Reporting."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-sources",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-sources",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Data Sources",
    "text": "Data Sources\n\n\nFinance Data: Information related to financial transactions, budgeting, and accounting.\nCRM Data: Customer Relationship Management data, including customer interactions, sales, and service records.\nOperations Data: Data concerning the day-to-day operations of a business, such as supply chain, inventory, and production.\nMore Data: Any additional data sources that contribute to the organization’s information ecosystem."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#etl-process-extract-transform-load",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#etl-process-extract-transform-load",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "ETL Process (Extract, Transform, Load)",
    "text": "ETL Process (Extract, Transform, Load)\n\n\nExtract: Data is collected from various sources, such as finance systems, CRM systems, and operations databases.\nTransform: The extracted data is cleaned, aggregated, and formatted to fit the data warehouse schema.\nLoad: The transformed data is loaded into the Data Warehouse, where it is stored and made available for analysis."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-warehouse-and-olap-engine",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-warehouse-and-olap-engine",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Data Warehouse and OLAP Engine",
    "text": "Data Warehouse and OLAP Engine\n\n\nData Warehouse: A centralized repository that stores integrated data from multiple sources, optimized for query and analysis.\nOLAP Engine (Online Analytical Processing): Tools that allow for complex analytical queries and multi-dimensional data analysis.\n\nExample: Analyzing sales trends over time, across different regions, or by product categories."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#analytic-reporting-and-advanced-analytics",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#analytic-reporting-and-advanced-analytics",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Analytic Reporting and Advanced Analytics",
    "text": "Analytic Reporting and Advanced Analytics\n\n\nAnalytic Reporting Engine: Produces reports and dashboards for users to visualize and understand the data.\n\nAd Hoc Reporting: Enables users to create custom reports on-demand.\nDashboards: Provides a visual summary of key performance indicators (KPIs) and metrics.\n\nAdvanced Analytics: Includes data mining, predictive modeling, and other sophisticated analytical techniques to uncover hidden patterns and insights."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#users-and-decision-making",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#users-and-decision-making",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Users and Decision-Making",
    "text": "Users and Decision-Making\n\n\nUsers: Business analysts, managers, and executives who use the IMS to make informed decisions.\nOutcome: The IMS enables data-driven decision-making, improving efficiency, reducing risks, and enhancing overall business performance."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#meta-data-and-data-dictionary-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#meta-data-and-data-dictionary-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Meta Data and Data Dictionary",
    "text": "Meta Data and Data Dictionary\n\n\n\nMetadata is essentially information about structured data. It can include details like the date and time a database or file was created, who created it, and what types of information it contains.\nA data dictionary is a more specific type of metadata that describes the structure, content, and format of a dataset. It’s like a guidebook and a codebook that provides a comprehensive list of all the variables or columns in a dataset, along with their definitions, data types, and other attributes.\n\nWithout it, you might get lost in a sea of information and struggle to make sense of it all."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#mtcars",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#mtcars",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "mtcars",
    "text": "mtcars\n\n\n\nThe mtcars data file provides information on various features of different brands of cars, including their engine size, horsepower, and fuel efficiency. The dataset is structured as a table, where each row represents a different car, and each column represents a different variable or feature of the cars."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-dictionary-for-mtcars",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#data-dictionary-for-mtcars",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Data Dictionary for mtcars",
    "text": "Data Dictionary for mtcars\n\n\n?mtcars"
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#learning-path-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#learning-path-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Learning Path",
    "text": "Learning Path\nThere are plenty of college courses to choose (course titles may vary by schools):\n\nDatabase Management Systems: This course focuses on the design, implementation, and management of databases, teaching students how to organize and manage data effectively.\nInformation Security and Privacy: This course covers the principles and practices of securing information and ensuring data privacy, preparing students to handle data security challenges.\nData Governance and Management: This course explores the governance and management of data assets, including data quality, data integration, and data lifecycle management.\nInformation Systems Analysis and Design: This course teaches students how to analyze business requirements and design information systems to meet organizational needs."
  },
  {
    "objectID": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#summary-1",
    "href": "lecture_slides/02_data_organization_decision/02_data_organization_decision.html#summary-1",
    "title": " MGMT 17300: Data Mining Lab ",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\nStructured Data: Highly organized and formatted data that is easily searchable (e.g., tables with rows and columns).\nDatabases: Used to store and manage structured data efficiently.\n\nTypes: Include relational databases (RDBMS) like MySQL and NoSQL databases like MongoDB.\nFunctionality: Provides tools for querying, updating, and managing large datasets.\n\nRelational Databases: Organizes data into tables that can be linked by shared keys.\n\nBenefits: Ensures data integrity and supports complex queries and transactions.\nKey Components: Tables, primary and foreign keys, SQL for data manipulation.\n\n\n\n\n\n\nNon-Relational Databases: NoSQL databases designed for unstructured data and scalability.\n- Advantages: Handle large-scale data across distributed systems more effectively than traditional RDBMS.\nMeta Data: Information describing other data, providing context and making it easier to understand.\nData Dictionary: Detailed description of dataset variables, ensuring consistent data usage."
  }
]